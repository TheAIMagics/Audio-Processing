{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61548ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04121931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CURRENT DIR E:\\INEURON_DATA\\Audio-Processing\\notebooks\n",
      "UPDATED DIR E:\\INEURON_DATA\\Audio-Processing\\notebooks\\unzip\n",
      "Total Labels: 2 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['cat', 'dog']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_dir = os.getcwd()\n",
    "print(\"CURRENT DIR\",os.getcwd())\n",
    "path = './unzip/'\n",
    "os.chdir(path)\n",
    "print(\"UPDATED DIR\",os.getcwd())\n",
    "labels = [name for name in os.listdir('.') if os.path.isdir(name)]\n",
    "print(f'Total Labels: {len(labels)} \\n')\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a66e5366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ImageFolder\n",
      "    Number of datapoints: 4159\n",
      "    Root location: ../data/spectrograms/\n",
      "    StandardTransform\n",
      "Transform: Compose(\n",
      "               Resize(size=(201, 81), interpolation=bilinear, max_size=None, antialias=None)\n",
      "               ToTensor()\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data_path = '../data/spectrograms/' \n",
    "dog_cat_dataset = datasets.ImageFolder(\n",
    "    root=data_path,\n",
    "    transform=transforms.Compose([transforms.Resize((201,81)),\n",
    "                                  transforms.ToTensor()\n",
    "                                  ])\n",
    ")\n",
    "print(dog_cat_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c47195fb",
   "metadata": {},
   "source": [
    "- `ImageFolder` automatically creates the image class labels and indices based on the folders for each audio class.\n",
    "- We'll use the `class_to_idx` to view the class mapping for the image dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef16cf83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Class category and index of the images: {'cat': 0, 'dog': 1}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class_map=dog_cat_dataset.class_to_idx\n",
    "print(\"\\nClass category and index of the images: {}\\n\".format(class_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00ab51dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 3327\n",
      "Testing size: 832\n"
     ]
    }
   ],
   "source": [
    "#split data to test and train\n",
    "#use 80% to train\n",
    "train_size = int(0.8 * len(dog_cat_dataset))\n",
    "test_size = len(dog_cat_dataset) - train_size\n",
    "dog_cat_train_dataset, dog_cat_test_dataset = torch.utils.data.random_split(dog_cat_dataset, [train_size, test_size])\n",
    "\n",
    "print(\"Training size:\", len(dog_cat_train_dataset))\n",
    "print(\"Testing size:\",len(dog_cat_test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846c2da9",
   "metadata": {},
   "source": [
    "Because the dataset was randomly split, let's count the training data to verify that the data has a fairly even distribution between the images in the `dog` and `cat` categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c46552e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 1718, 0: 1609})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# labels in training set\n",
    "train_classes = [label for _, label in dog_cat_train_dataset]\n",
    "Counter(train_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4eb7f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    dog_cat_train_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=0,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    dog_cat_test_dataset,\n",
    "    batch_size=15,\n",
    "    num_workers=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945aeeb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b07d55e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(51136, 50)\n",
    "        self.fc2 = nn.Linear(50, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        #x = x.view(x.size(0), -1)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return F.log_softmax(x,dim=1)  \n",
    "\n",
    "model = CNNet().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "439dd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function used to determine best parameters\n",
    "cost = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# used to create optimal parameters\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Create the training function\n",
    "\n",
    "def train(dataloader, model, loss, optimizer):\n",
    "    model.train()\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, Y) in enumerate(dataloader):\n",
    "        \n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = cost(pred, Y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f'loss: {loss:>7f}  [{current:>5d}/{size:>5d}]')\n",
    "\n",
    "\n",
    "# Create the validation/test function\n",
    "\n",
    "def test(dataloader, model):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, (X, Y) in enumerate(dataloader):\n",
    "            X, Y = X.to(device), Y.to(device)\n",
    "            pred = model(X)\n",
    "\n",
    "            test_loss += cost(pred, Y).item()\n",
    "            correct += (pred.argmax(1)==Y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= size\n",
    "    correct /= size\n",
    "\n",
    "    print(f'\\nTest Error:\\nacc: {(100*correct):>0.1f}%, avg loss: {test_loss:>8f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcc9ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 0.704774  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 6\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 7\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 8\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 9\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 10\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 11\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 12\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 13\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 14\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Epoch 15\n",
      "-------------------------------\n",
      "loss: 0.693147  [    0/ 3327]\n",
      "loss: 0.693147  [ 1500/ 3327]\n",
      "loss: 0.693147  [ 3000/ 3327]\n",
      "\n",
      "Test Error:\n",
      "acc: 50.7%, avg loss: 0.046654\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 15\n",
    "\n",
    "for t in range(epochs):\n",
    "    print(f'Epoch {t+1}\\n-------------------------------')\n",
    "    train(train_dataloader, model, cost, optimizer)\n",
    "    test(test_dataloader, model)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df62e4c8",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d8e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss, correct = 0, 0\n",
    "class_map = ['no', 'yes']\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch, (X, Y) in enumerate(test_dataloader):\n",
    "        X, Y = X.to(device), Y.to(device)\n",
    "        pred = model(X)\n",
    "        print(\"Predicted:\\nvalue={}, class_name= {}\\n\".format(pred[0].argmax(0),class_map[pred[0].argmax(0)]))\n",
    "        print(\"Actual:\\nvalue={}, class_name= {}\\n\".format(Y[0],class_map[Y[0]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c284d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urban",
   "language": "python",
   "name": "urban"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
